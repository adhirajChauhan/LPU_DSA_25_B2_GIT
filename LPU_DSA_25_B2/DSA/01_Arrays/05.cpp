/*
Time complexity - It is a way to express how the running time of an algorithm increases with the input size.

Notations ->
1. Big O -> represents the upper bound of running time. it gives worst-case scanerio of an algorithm, (describes the maximim time an algorithm can take)
2. Theta -> average case
3. Omega -> reperesents the lower bound (gives the best-case scanerio)


Examples ->

1. O(1) -> Constant time -> the time taken doesn't depend on input size.The algo always runs in same time.

2. O(log n) -> Logarithmic time -> time grows logarithmically as the input size increases. Often seen in algorithms that divide the input in half like binary search

3. O(n) -> Linear Time -> time grows directly in proportion to input size

4. O(n log n) -> Linearithmic Time -> mix of linear and logarithmic time, common in divide and conquer, like quick and merge sort

5. O(n^2) -> Quadratic time -> time grows proportionally to the square of input size, often senn in algorithms with nested loops

6. O(2^n) -> Exponential time -> the time doubles with each additional element, common in recursive algorithms
*/


#include<iostream>
using namespace std;
 
int main()
{
 
}